{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joycenerd/yolov5-svhn-detection/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOjOB4VtAaNN"
   },
   "source": [
    "# Step 0: Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OA0ulv5qAAK-",
    "outputId": "d2ac4618-e803-42bc-bade-491bf3d72054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 17 07:31:46 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P8    27W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Make sure you use the Colab GPU to run the testing phase\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzC9Kd6sAy6s"
   },
   "source": [
    "# Step 1: Git clone your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJXVHsenA2QU",
    "outputId": "06d1fed8-cdec-4f5b-efa1-a8b90ad11b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5-svhn-detection'...\n",
      "remote: Enumerating objects: 109, done.\u001b[K\n",
      "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
      "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
      "remote: Total 109 (delta 25), reused 100 (delta 22), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (109/109), 181.64 KiB | 2.36 MiB/s, done.\n",
      "Resolving deltas: 100% (25/25), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/joycenerd/yolov5-svhn-detection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rL1aCMwjCiWz"
   },
   "source": [
    "# Step 2: Install your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEi4yJ3QCouL",
    "outputId": "962762b3-3d7b-4198-964a-e6e4721c9011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/yolov5-svhn-detection/yolov5\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
      "Collecting PyYAML>=5.3.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.7.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
      "Collecting thop\n",
      "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.41.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.6.0)\n",
      "Installing collected packages: thop, PyYAML\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n",
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5-svhn-detection/yolov5/\n",
    "!pip install -r requirements.txt\n",
    "!pip install googledrivedownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_CN3AyvD451",
    "outputId": "5bc91a50-229c-4f9d-9ce8-8c197dec9595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/yolov5-svhn-detection/yolov5\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "ROOT = os.getcwd()  # YOLOv5 root directory\n",
    "print(ROOT)\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (\n",
    "    LOGGER,\n",
    "    check_file,\n",
    "    check_img_size,\n",
    "    check_imshow,\n",
    "    check_requirements,\n",
    "    colorstr,\n",
    "    increment_path,\n",
    "    non_max_suppression,\n",
    "    print_args,\n",
    "    scale_coords,\n",
    "    strip_optimizer,\n",
    "    xyxy2xywh,\n",
    ")\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAb_xc0oGKhS"
   },
   "source": [
    "# Step 3: Load model\n",
    "\n",
    "If you want to reproduce our results, please download the checkpoint from https://github.com/joycenerd/yolov5-svhn-detection. Download from this repo's lastest release that has a file name as 'yolov5_best.pt'. And upload the downloaded checkpoint into this Google Colab workspace. (downloaded checkpoint path: /content/best_ckpt.pt)\n",
    "\n",
    "If you want to play around with your own model just upload your own checkpoint file here and modified the `weights` path below.\n",
    "\n",
    "<font color=#FF0000>Note: We use YOLOv5 in this repo https://github.com/ultralytics/yolov5 as our model. Your checkpoint `model_state_dict` should be compatible with our model.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYg_j6JrHHuG",
    "outputId": "9bbf594f-32bb-4ab8-dc48-941ad1192895"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 5e43ba7 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93\n",
      "Val mAP: [    0.54181]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 213 layers, 7037095 parameters, 0 gradients, 15.9 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "weights = [\"/content/yolov5_best.pt\"]\n",
    "device = select_device(\"0\")\n",
    "model = DetectMultiBackend(weights, device=device, dnn=False)\n",
    "stride, names, pt, jit, onnx = (\n",
    "    model.stride,\n",
    "    model.names,\n",
    "    model.pt,\n",
    "    model.jit,\n",
    "    model.onnx,\n",
    ")\n",
    "imgsz = check_img_size(imgsz=640, s=stride)  # check image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQKx62jkqigt"
   },
   "source": [
    "# Step 4: Wget testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NBSSYW_qlqt",
    "outputId": "19666be4-7d29-4f1b-8089-a7e7efd196f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1Fm-avdeNgzhPxhvia0iw9yZzcoOggy7I into ./test.zip... Done.\n",
      "Unzipping...Done.\n",
      "Test data size: 13068\n"
     ]
    }
   ],
   "source": [
    "# 1. Download the testing data\n",
    "\n",
    "gdd.download_file_from_google_drive(\n",
    "    file_id=\"1Fm-avdeNgzhPxhvia0iw9yZzcoOggy7I\", dest_path=\"./test.zip\", unzip=True\n",
    ")\n",
    "# Dataloader\n",
    "source = \"test\"\n",
    "dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt and not jit)\n",
    "bs = 1  # batch_size\n",
    "print(f\"Test data size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmuC_BlOr15m"
   },
   "source": [
    "# Step 5: Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm_swqoBr6OJ",
    "outputId": "9154b8e6-9469-422d-9896-cfabfce86599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference time per image:  0.022769753932952882\n"
     ]
    }
   ],
   "source": [
    "# Test your inference time\n",
    "TEST_IMAGE_NUMBER = 100  # This number is fixed.\n",
    "\n",
    "dt, seen = [0.0, 0.0, 0.0], 0\n",
    "conf_thres = 0.25\n",
    "iou_thres = 0.45\n",
    "classes = None\n",
    "agnostic_nms = False\n",
    "max_det = 1000\n",
    "half = False\n",
    "cnt = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for path, im, im0s, vid_cap, s in dataset:\n",
    "    # t1 = time_sync()\n",
    "    im = torch.from_numpy(im).to(device)\n",
    "    im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "    im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    if len(im.shape) == 3:\n",
    "        im = im[None]  # expand for batch dim\n",
    "    # t2 = time_sync()\n",
    "    # dt[0] += t2 - t1\n",
    "\n",
    "    # Inference\n",
    "    # visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "    pred = model(im, augment=False, visualize=False)\n",
    "    # t3 = time_sync()\n",
    "    # dt[1] += t3 - t2\n",
    "\n",
    "    # NMS\n",
    "    pred = non_max_suppression(\n",
    "        pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det\n",
    "    )\n",
    "    # dt[2] += time_sync() - t3\n",
    "    cnt += 1\n",
    "    if cnt == TEST_IMAGE_NUMBER:\n",
    "        break\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\nInference time per image: \", (end_time - start_time) / TEST_IMAGE_NUMBER)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMwTRY4jES52AAhaWMtIQW3",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "inference-yolov5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
